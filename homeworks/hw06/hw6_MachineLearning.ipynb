{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Fall 2018: Homework 06 \n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "**Authors:** Sana Iqbal (Part 1, 2, 3)\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import otter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.a Read __`diabetesdata.csv`__ file into a pandas dataframe. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellipsis\n"
     ]
    }
   ],
   "source": [
    "#Read data & print it\n",
    "data = ...\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Calculate the percentage of NaN values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NullsPerColumn = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.c Calculate the TOTAL percent of ROWS with NaN values in the dataframe (make sure values are floats).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PercentNull =  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.d Split __`data`__  into  __`train_df`__ and __`test_df`__  with 15% test split.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split values\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.e Replace the Nan values in  __`train_df`__ and __`test_df`__  with the mean of EACH feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df =...\n",
    "test_df =...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.f Split __`train_df`__ & __`test_df`__   into  __`X_train`__, __`Y_train`__  and __`X_test`__, __`Y_test`__. __`Y_train`__  and __`Y_test`__ should only have the column we are trying to predict,  __`IsDiabetic`__.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = ...\n",
    "Y_train = ...\n",
    "X_test  = ...\n",
    "Y_test = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.g Use this dataset to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = ... # use newton-cg solver and 'ovr' for multi_class\n",
    "logreg.fit(...)\n",
    "logreg_train_acc = ...\n",
    "logreg_test_acc = ...\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "\n",
    "perceptron = ...\n",
    "perceptron.fit(...)\n",
    "perceptron_train_acc = ...\n",
    "perceptron_test_acc = ...\n",
    "print ('perceptron training acuracy= ',perceptron_train_acc)\n",
    "print('perceptron test accuracy= ',perceptron_test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adaboost\n",
    "adaboost = ...\n",
    "adaboost.fit(...)\n",
    "adaboost_train_acc = ...\n",
    "adaboost_test_acc = ...\n",
    "print ('adaboost training acuracy= ',adaboost_train_acc)\n",
    "print('adaboost test accuracy= ',adaboost_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest = ...\n",
    "random_forest.fit(...)\n",
    "random_forest_train_acc = ...\n",
    "random_forest_test_acc = ...\n",
    "print('random_forest training acuracy= ',random_forest_train_acc)\n",
    "print('random_forest test accuracy= ',random_forest_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.h Is mean imputation is the best type of imputation to use? Why or why not? What are some other ways to impute the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better = ... # [boolean] change this to be True if you believe mean imputation is the best imputation to use, and False otherwise\n",
    "explanation = ... # [string] write why or why not here, and other ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__2.a Add columns __`BMI_band`__ & __`Pedigree_band`__  to  a new dataframe called __`data2`__  by cutting __`BMI`__ & __`Pedigree`__ into 3 intervals. PRINT the first 5 rows of __`data2`__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "data2 = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.b Print the category intervals for __`BMI_band`__ & __`Pedigree_band`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('BMI_Band_Interval: ' + ...)\n",
    "print('Pedigree_Band_Interval: ' + '...)\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.c Group __`data`__ by __`Pedigree_band`__ & determine ratio of diabetic in each band.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    " \n",
    "pedigree_DiabeticRatio = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.d Group  __`data`__ by __`BMI_band`__ & determine ratio of diabetic in each band.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "BMI_DiabeticRatio = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.e Convert these features - 'BP','insulin','BMI' and 'Pedigree'   into categorical values by mapping different bands of values of these features to integers 0,1,2 in a dataframe called `data3`.__  \n",
    " \n",
    "HINT: USE pd.cut with bin=3 to create 3 bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "data3 = ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__2.f Now consider the original dataset again, instead of generalizing the NAN values with the mean of the feature we will try assigning values to NANs based on some hypothesis. For example for age we assume that the relation between BMI and BP of people is a reflection of the age group. We can have 9 types of BMI and BP relations and our aim is to find the median age of each of that group:__\n",
    "\n",
    "Your Age guess matrix will look like this:  \n",
    "\n",
    "| BMI | 0       | 1      | 2  |\n",
    "|-----|-------------|------------- |----- |\n",
    "| BP  |             |              |      |\n",
    "| 0   | a00         | a01          | a02  |\n",
    "| 1   | a10         | a11          | a12  |\n",
    "| 2   | a20         | a21          |  a22 |\n",
    "\n",
    "\n",
    "__Create a guess_matrix  for NaN values of *'Age'* ( using 'BMI' and 'BP')  and  *'glucoseLevel'*  (using 'BP' and 'Pedigree') for the given dataset and assign values accordingly to the NaNs in 'Age' or *'glucoseLevel'* .__\n",
    "\n",
    "\n",
    "Refer to how we guessed age in the titanic notebook in the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "guess_matrix_age = ...\n",
    "guess_matrix_glucoseLevel = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__2.g Now, convert 'glucoseLevel' and 'Age' features also to categorical variables of 4 categories each in a dataframe called `data4`. PRINT the head of `data4`__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "data4 = ...\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.h Use this dataset (with all features in categorical form) to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = ...\n",
    "X_train = ...\n",
    "Y_train = ...\n",
    "X_test  = ...\n",
    "Y_test= ...\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = ...\n",
    "logreg.fit(...)\n",
    "logreg_train_acc = ...\n",
    "logreg_test_acc = ...\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perceptron\n",
    "perceptron = ...\n",
    "perceptron.fit(...)\n",
    "perceptron_train_acc = ...\n",
    "perceptron_test_acc = ...\n",
    "print ('perceptron training acuracy= ',perceptron_train_acc)\n",
    "print('perceptron test accuracy= ',perceptron_test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "random_forest = ...\n",
    "random_forest.fit(...)\n",
    "random_forest_train_acc = ...\n",
    "random_forest_test_acc = ...\n",
    "print ('random_forest training acuracy= ',random_forest_train_acc)\n",
    "print('random_forest test accuracy= ',random_forest_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
